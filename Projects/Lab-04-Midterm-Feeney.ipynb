{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0fd2a7",
   "metadata": {},
   "source": [
    "## Using Python to Integrate MongoDB Data into an ETL Process\n",
    "Modern Data Warehousing and Analytics solutions frequently use languages like Python or Scala to extract data from numerous sources, including relational database management systems, NoSQL database systems, real-time streaming endpoints and Data Lakes. These languages can then be used to perform many types of transformation before then loading the data into a variety of destinations including file systems and data warehouses. This data can then be consumed by data scientists or business analysts.\n",
    "\n",
    "In this lab you will build upon the **Northwind_DW2** dimensional database from Lab 3; however, you will be integrating new data sourced from an instance of MongoDB. The new data will be concerned with new business processes; inventory and purchasing. You will continue to interact with both the source systems (MongoDB and MySQL), and the destination system (the Northwind_DW2 data warehouse) from a remote client running Python (Jupyter Notebooks). \n",
    "\n",
    "Just as in Lab 3, you will fetch data into Pandas DataFrames, perform all the necessary transformations in-memory on the client, and then push the newly transformed DataFrame to the RDBMS data warehouse using a Pandas function that will create the table and fill it with data with a single operation.\n",
    "\n",
    "### Prerequisites:\n",
    "#### Import the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8b95ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c629e4",
   "metadata": {},
   "source": [
    "#### Declare & Assign Connection Variables for the MongoDB Server, the MySQL Server & Databases with which You'll be Working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28890801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Connection String: mongodb://localhost:27017/\n",
      "Atlas Connection String: mongodb+srv://maf9tga:Passw0rd123@cluster0.8rqtmzl.mongodb.net/?retryWrites=true&w=majority\n"
     ]
    }
   ],
   "source": [
    "#mysql connection variables. Had to use the ones from lab 3 because the ones provided in lab 4 did not work\n",
    "host_name = \"localhost\"\n",
    "host_ip = \"127.0.0.1\"\n",
    "port = \"3306\"\n",
    "user_id = \"root\"\n",
    "pwd = \"Passw0rd123\"\n",
    "\n",
    "#mysql_uid = \"root\"\n",
    "#mysql_pwd = \"Passw0rd123\"\n",
    "#mysql_host = \"ds2002-mysql.mysql.database.azure.com\"\n",
    "#mongo db connection variables\n",
    "atlas_cluster_name = \"cluster0.zibbf\"\n",
    "atlas_user_name = \"maf9tga\"\n",
    "atlas_password = \"Passw0rd123\"\n",
    "\n",
    "conn_str = {\"local\" : f\"mongodb://localhost:27017/\",\n",
    "    \"atlas\" : f\"mongodb+srv://maf9tga:Passw0rd123@cluster0.8rqtmzl.mongodb.net/?retryWrites=true&w=majority\"\n",
    "}\n",
    "\n",
    "src_dbname = \"sakila_rental_fact\"\n",
    "dst_dbname = \"sakila_dw2\"\n",
    "\n",
    "print(f\"Local Connection String: {conn_str['local']}\")\n",
    "print(f\"Atlas Connection String: {conn_str['atlas']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21928a06",
   "metadata": {},
   "source": [
    "#### Define Functions for Getting Data From and Setting Data Into Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eabb5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_dataframe(user_id, pwd, host_name, db_name, sql_query):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    conn = sqlEngine.connect()\n",
    "    dframe = pd.read_sql(sql_query, conn);\n",
    "    conn.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def get_mongo_dataframe(connect_str, db_name, collection, query):\n",
    "    '''Create a connection to MongoDB'''\n",
    "    client = pymongo.MongoClient(connect_str)\n",
    "    \n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    client.close()\n",
    "    return dframe\n",
    "#used set_dataframe function from lab 3 as well\n",
    "def set_dataframe(user_id, pwd, host_name, db_name, df, table_name, pk_column, db_operation):\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        sqlEngine.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "#def set_dataframe(user_id, pwd, db_name, host_name, df, table_name, pk_column, db_operation):\n",
    "   # '''Create a connection to the MySQL database'''\n",
    "   # conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    #sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "   # connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "   # if db_operation == \"insert\":\n",
    "     #   df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "     #   sqlEngine.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "   # elif db_operation == \"update\":\n",
    "     #   df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "   # connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a3a43",
   "metadata": {},
   "source": [
    "#### Populate MongoDB with Source Data\n",
    "You only need to run this cell once; however, the operation is *idempotent*.  In other words, it can be run multiple times without changing the end result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9772c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(conn_str[\"atlas\"])\n",
    "db = client[src_dbname]\n",
    "\n",
    "# Gets the path of the Current Working Directory for this Notebook, and then Appends the 'data' directory.\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "json_files = {\"customer\" : 'sakila_customer.json',\n",
    "              \"film\" : 'sakila_film.json',\n",
    "              \"inventory\" : 'sakila_inventory.json',\n",
    "              \"staff\" : 'sakila_staff.json',\n",
    "              \"rental_fact\" : 'rental_fact.json'\n",
    "             }\n",
    "\n",
    "for file in json_files:\n",
    "    db.drop_collection(file)\n",
    "    json_file = os.path.join(data_dir, json_files[file])\n",
    "    with open(json_file, 'r') as openfile:\n",
    "        json_object = json.load(openfile)\n",
    "        file = db[file]\n",
    "        result = file.insert_many(json_object)\n",
    "        #print(f\"{file} was successfully loaded.\")\n",
    "\n",
    "        \n",
    "client.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41747a78",
   "metadata": {},
   "source": [
    "### 1.0. Create and Populate the Fact Table. \n",
    "#### I have already added the dimension tables to sakila_dw2 previously. Now all I need to do is load my already made (in MySQL) fact table in\n",
    "#### 1.1. Extract Data from the Source MongoDB Collections Into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2751d14-1795-4496-8d19-0aa239286d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>rental_date</th>\n",
       "      <th>inventory_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>return_date</th>\n",
       "      <th>staff_id</th>\n",
       "      <th>last_update</th>\n",
       "      <th>film_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>rental_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2005-05-24 22:53:30</td>\n",
       "      <td>367</td>\n",
       "      <td>130</td>\n",
       "      <td>2005-05-26 22:04:30</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-14 20:52:24</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2005-05-24 22:54:33</td>\n",
       "      <td>1525</td>\n",
       "      <td>459</td>\n",
       "      <td>2005-05-28 19:40:33</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-14 20:52:24</td>\n",
       "      <td>333</td>\n",
       "      <td>2</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rental_id          rental_date  inventory_id  customer_id  \\\n",
       "0          1  2005-05-24 22:53:30           367          130   \n",
       "1          2  2005-05-24 22:54:33          1525          459   \n",
       "\n",
       "           return_date  staff_id          last_update  film_id  store_id  \\\n",
       "0  2005-05-26 22:04:30         1  2023-03-14 20:52:24       80         1   \n",
       "1  2005-05-28 19:40:33         1  2023-03-14 20:52:24      333         2   \n",
       "\n",
       "   rental_rate  \n",
       "0         2.99  \n",
       "1         2.99  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Extract data from the \"rental_fact\" collection\n",
    "query = {}\n",
    "collection = \"rental_fact\"\n",
    "\n",
    "df_rental_fact = get_mongo_dataframe(conn_str['atlas'], src_dbname, collection, query)\n",
    "df_rental_fact.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd16f44",
   "metadata": {},
   "source": [
    "#### 1.3. Load the Transformed DataFrames into the New Data Warehouse by Creating New Tables\n",
    "\n",
    "Here we will call our **set_dataframe( )** function to create each dimension table. This function expects a number of parameters including the usual connection information (e.g., user_id, password, MySQL server name and database), the *table_name* we need to assign to the table, the *pandas DataFrame* we crafted to define & populate the table, the *name* we need to assign to the *primary_key* column, and finally, the database operation (insert or update). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c5d4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df_rental_fact\n",
    "table_name = 'rental_fact'\n",
    "primary_key = 'rental_id'\n",
    "db_operation = \"insert\"\n",
    "\n",
    "set_dataframe(user_id, pwd, host_name, dst_dbname, dataframe, table_name, primary_key, db_operation)\n",
    "#(user_id, pwd, host_name, db_name, df, table_name, pk_column, db_operation)\n",
    "#host_name = \"localhost\"\n",
    "#host_ip = \"127.0.0.1\"\n",
    "#port = \"3306\"\n",
    "#user_id = \"root\"\n",
    "#pwd = \"Passw0rd123\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2411d8e",
   "metadata": {},
   "source": [
    "#### 1.4. Validate that the Fact Table was Created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e4ed928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>rental_date</th>\n",
       "      <th>inventory_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>return_date</th>\n",
       "      <th>staff_id</th>\n",
       "      <th>last_update</th>\n",
       "      <th>film_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>rental_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2005-05-24 22:53:30</td>\n",
       "      <td>367</td>\n",
       "      <td>130</td>\n",
       "      <td>2005-05-26 22:04:30</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-14 20:52:24</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2005-05-24 22:54:33</td>\n",
       "      <td>1525</td>\n",
       "      <td>459</td>\n",
       "      <td>2005-05-28 19:40:33</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-14 20:52:24</td>\n",
       "      <td>333</td>\n",
       "      <td>2</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rental_id          rental_date  inventory_id  customer_id  \\\n",
       "0          1  2005-05-24 22:53:30           367          130   \n",
       "1          2  2005-05-24 22:54:33          1525          459   \n",
       "\n",
       "           return_date  staff_id          last_update  film_id  store_id  \\\n",
       "0  2005-05-26 22:04:30         1  2023-03-14 20:52:24       80         1   \n",
       "1  2005-05-28 19:40:33         1  2023-03-14 20:52:24      333         2   \n",
       "\n",
       "   rental_rate  \n",
       "0         2.99  \n",
       "1         2.99  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_rental_fact = \"SELECT * FROM sakila_dw2.rental_fact;\"\n",
    "df_rental_fact = get_sql_dataframe(user_id, pwd, host_name, dst_dbname, sql_rental_fact) #(user_id, pwd, host_name, db_name, sql_query)\n",
    "df_rental_fact.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
